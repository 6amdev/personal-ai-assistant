"""Memory Handler - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥"""
import sys
from pathlib import Path
from typing import List, Dict
import os

# ‡∏õ‡∏¥‡∏î ChromaDB telemetry
os.environ["ANONYMIZED_TELEMETRY"] = "False"

# ‡πÄ‡∏û‡∏¥‡πà‡∏° root folder ‡πÄ‡∏Ç‡πâ‡∏≤ path
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain.memory import ConversationBufferMemory

try:
    from config import CHROMA_DB_DIR, COLLECTION_NAME, LLM_MODEL
except ImportError:
    CHROMA_DB_DIR = "./data/chroma_db"
    COLLECTION_NAME = "personal_assistant"
    LLM_MODEL = "llama3.1:8b"


class MemoryHandler:
    def __init__(self):
        """Initialize memory systems"""
        print("üíæ Initializing memory...")
        
        # Embeddings - ‡πÉ‡∏ä‡πâ nomic-embed-text (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤!)
        ##self.embeddings = OllamaEmbeddings(model="nomic-embed-text")
        self.embeddings = OllamaEmbeddings(model="llama3.1:8b")
        
        # Long-term memory (ChromaDB)
        self.vectorstore = Chroma(
            collection_name=COLLECTION_NAME,
            embedding_function=self.embeddings,
            persist_directory=CHROMA_DB_DIR
        )
        
        # Short-term memory (Conversation)
        self.conversation_memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        print("‚úÖ Memory ready!")
    
    def add_documents(self, texts: List[str], metadatas: List[dict] = None):
        """
        Add documents to long-term memory (with batch processing)
        
        Args:
            texts: List of text chunks
            metadatas: Optional metadata for each chunk
        """
        total = len(texts)
        batch_size = 20  # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 20 chunks ‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        
        print(f"üìö Adding {total} chunks to memory...")
        
        for i in range(0, total, batch_size):
            batch_texts = texts[i:i+batch_size]
            batch_metas = metadatas[i:i+batch_size] if metadatas else None
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å batch ‡∏ô‡∏µ‡πâ
            self.vectorstore.add_texts(texts=batch_texts, metadatas=batch_metas)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            processed = min(i+batch_size, total)
            print(f"   ‚úÖ {processed}/{total} chunks")
        
        print(f"‚úÖ Successfully added all {total} chunks!")
    
    def search(self, query: str, k: int = 3) -> List[Dict]:
        """
        Search similar documents
        
        Args:
            query: Search query
            k: Number of results
            
        Returns:
            List of documents with metadata
        """
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        
        # Format results
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                'content': doc.page_content,
                'metadata': doc.metadata,
                'score': score
            })
        
        return formatted_results
    
    def get_context(self, query: str, k: int = 3) -> str:
        """
        Get context for query (formatted for LLM)
        
        Args:
            query: User query
            k: Number of documents to retrieve
            
        Returns:
            Formatted context string
        """
        results = self.search(query, k=k)
        
        if not results:
            return ""
        
        context = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:\n\n"
        for i, result in enumerate(results, 1):
            context += f"{i}. {result['content']}\n"
            if 'source' in result['metadata']:
                context += f"   (‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤: {result['metadata']['source']})\n"
            context += "\n"
        
        return context
    
    def clear_conversation(self):
        """Clear conversation memory"""
        self.conversation_memory.clear()
        print("üóëÔ∏è Cleared conversation")
    
    def count_documents(self) -> int:
        """Count total documents in vector store"""
        try:
            collection = self.vectorstore._collection
            return collection.count()
        except:
            return 0
    
    def get_all_sources(self) -> List[str]:
        """
        Get list of all unique document sources
        
        Returns:
            List of source filenames
        """
        try:
            collection = self.vectorstore._collection
            results = collection.get()
            
            if not results or 'metadatas' not in results:
                return []
            
            # Extract unique sources
            sources = set()
            for metadata in results['metadatas']:
                if metadata and 'source' in metadata:
                    sources.add(metadata['source'])
            
            return sorted(list(sources))
        except Exception as e:
            print(f"Error getting sources: {e}")
            return []
    
    def delete_by_source(self, source: str) -> int:
        """
        Delete all documents from a specific source
        
        Args:
            source: Source filename to delete
            
        Returns:
            Number of documents deleted
        """
        try:
            collection = self.vectorstore._collection
            
            # Get all documents
            results = collection.get()
            
            if not results or 'ids' not in results:
                return 0
            
            # Find IDs with matching source
            ids_to_delete = []
            for i, metadata in enumerate(results['metadatas']):
                if metadata and metadata.get('source') == source:
                    ids_to_delete.append(results['ids'][i])
            
            # Delete
            if ids_to_delete:
                collection.delete(ids=ids_to_delete)
                print(f"üóëÔ∏è Deleted {len(ids_to_delete)} chunks from {source}")
            
            return len(ids_to_delete)
        except Exception as e:
            print(f"Error deleting source: {e}")
            return 0
    
    def clear_all_documents(self) -> bool:
        """
        Clear all documents from vector store
        ‡πÉ‡∏ä‡πâ API ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå
        
        Returns:
            True if successful
        """
        try:
            collection = self.vectorstore._collection
            
            # Get all IDs
            results = collection.get()
            
            if results and 'ids' in results and results['ids']:
                # Delete all by IDs
                collection.delete(ids=results['ids'])
                print(f"üóëÔ∏è Deleted {len(results['ids'])} documents")
                return True
            else:
                print("‚ÑπÔ∏è No documents to delete")
                return True
                
        except Exception as e:
            print(f"Error clearing documents: {e}")
            return False


# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
if __name__ == "__main__":
    print("Testing Memory Handler...")
    memory = MemoryHandler()
    
    print("\nüìù Adding test documents...")
    memory.add_documents([
        "‡∏ú‡∏°‡∏ä‡∏∑‡πà‡∏≠ John Doe",
        "‡∏ú‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå",
        "‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå 5 ‡∏õ‡∏µ",
        "‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç Python ‡πÅ‡∏•‡∏∞ AI"
    ], metadatas=[
        {'source': 'profile.txt'},
        {'source': 'profile.txt'},
        {'source': 'profile.txt'},
        {'source': 'profile.txt'}
    ])
    
    print(f"\nüìä Total documents: {memory.count_documents()}")
    
    print("\nüîç Searching...")
    query = "‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"
    context = memory.get_context(query, k=2)
    print(f"Query: {query}")
    print(f"\nContext:\n{context}")
    
    print("\nüìÑ All sources:")
    sources = memory.get_all_sources()
    for source in sources:
        print(f"  - {source}")