# ğŸ’¬ Personal AI Assistant

> AI Chatbot à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸ˆà¸²à¸à¹€à¸­à¸à¸ªà¸²à¸£à¸‚à¸­à¸‡à¸„à¸¸à¸“ - à¸Ÿà¸£à¸µ 100% à¸£à¸±à¸™à¸šà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸­à¸‡!

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Ollama](https://img.shields.io/badge/ollama-required-orange.svg)](https://ollama.com)
[![Made by](https://img.shields.io/badge/made%20by-6amdev-red.svg)](https://github.com/6amdev)

## âœ¨ Features

- ğŸ¤– **Local LLM** - Llama 3.1 8B (via Ollama)
- ğŸ’¾ **Persistent Memory** - à¸ˆà¸³à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¹à¸¥à¸°à¹€à¸­à¸à¸ªà¸²à¸£à¸–à¸²à¸§à¸£
- ğŸ“š **RAG Support** - à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¹€à¸­à¸à¸ªà¸²à¸£
- ğŸ‡¹ğŸ‡­ **Thai Language** - à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢
- ğŸ”’ **100% Private** - à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸­à¸­à¸à¸ˆà¸²à¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡
- ğŸ†“ **Free** - Open source à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢
- ğŸ“„ **Multi-format** - TXT, PDF, DOCX, MD

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/6amdev/personal-ai-assistant.git
cd personal-ai-assistant
pip install -r requirements.txt
ollama pull llama3.1:8b
streamlit run app.py
```

à¹€à¸›à¸´à¸” browser à¸—à¸µà¹ˆ `http://localhost:8501`

## ğŸ“– Usage

**Chat:** à¸à¸´à¸¡à¸à¹Œà¸„à¸³à¸–à¸²à¸¡ â†’ AI à¸•à¸­à¸š  
**Upload:** Sidebar â†’ ğŸ“¤ Upload Documents â†’ à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ  
**Manage:** ğŸ“„ View Documents â†’ à¸¥à¸šà¹„à¸”à¹‰à¸—à¸µà¸¥à¸°à¹„à¸Ÿà¸¥à¹Œ

## ğŸ› ï¸ Tech Stack

### Core Technologies

| Technology | Purpose | Why We Use It |
|-----------|---------|---------------|
| **[Streamlit](https://streamlit.io)** | Web UI Framework | à¸ªà¸£à¹‰à¸²à¸‡ web app à¸”à¹‰à¸§à¸¢ Python à¸‡à¹ˆà¸²à¸¢à¹† à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ HTML/CSS |
| **[LangChain](https://langchain.com)** | LLM Framework | à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ LLM, Memory, à¹à¸¥à¸° Tools à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ |
| **[Llama 3.1 8B](https://ai.meta.com/llama/)** | Language Model | Open source LLM à¸ˆà¸²à¸ Meta à¸‰à¸¥à¸²à¸”à¹à¸¥à¸°à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢ |
| **[Ollama](https://ollama.com)** | LLM Runtime | à¸£à¸±à¸™ LLM à¸šà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸£à¸²à¹„à¸”à¹‰ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ API |
| **[ChromaDB](https://trychroma.com)** | Vector Database | à¹€à¸à¹‡à¸š embeddings à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¹‰à¸™à¸«à¸²à¹€à¸­à¸à¸ªà¸²à¸£à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ |
| **Python 3.11** | Backend Language | à¸ à¸²à¸©à¸²à¸«à¸¥à¸±à¸à¸‚à¸­à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ |

### Document Processing

| Library | Purpose |
|---------|---------|
| **pypdf** | à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ PDF |
| **python-docx** | à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ DOCX (Word) |
| **unstructured** | à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹€à¸­à¸à¸ªà¸²à¸£à¸«à¸¥à¸²à¸¢à¸£à¸¹à¸›à¹à¸šà¸š |

### AI Components

**RAG (Retrieval-Augmented Generation):**
- à¹à¸›à¸¥à¸‡à¹€à¸­à¸à¸ªà¸²à¸£à¹€à¸›à¹‡à¸™ embeddings (à¸•à¸±à¸§à¹€à¸¥à¸‚)
- à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸„à¸³à¸–à¸²à¸¡
- à¸ªà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰ LLM à¸­à¹ˆà¸²à¸™à¹à¸¥à¸°à¸•à¸­à¸š

**Embeddings:**
- à¹ƒà¸Šà¹‰ Llama 3.1 à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™ vectors
- à¹€à¸à¹‡à¸šà¹ƒà¸™ ChromaDB à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹à¸šà¸š semantic

**Memory:**
- Short-term: à¸ˆà¸³à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (ConversationBufferMemory)
- Long-term: à¸ˆà¸³à¹€à¸­à¸à¸ªà¸²à¸£à¸–à¸²à¸§à¸£ (ChromaDB)

## ğŸ—ï¸ Architecture

```
User Interface (Streamlit)
    â†“
Application Layer (LangChain)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               â”‚              â”‚
 Memory      LLM (Llama 3.1)   â”‚
 (ChromaDB)   (via Ollama)     â”‚
```

## ğŸ“Š Performance

| Task | Time |
|------|------|
| Chat Response    | 3-8s   |
| Upload (1 file)  | 5-10s  |
| Upload (5 files) | 15-30s |
| Semantic Search  | <1s    |

*Tested: RTX 4070 Ti 12GB*

## ğŸ› Troubleshooting

**Ollama not found:**
```bash
ollama --version
```

**Model not found:**
```bash
ollama pull llama3.1:8b
```

**Import error:**
```bash
pip install -r requirements.txt
```

**Slow performance:**
- à¹ƒà¸Šà¹‰ GPU (à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ CUDA drivers)
- à¸¥à¸” chunk size à¹ƒà¸™ `document_processor.py`
- à¹ƒà¸Šà¹‰ model à¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸² à¹€à¸Šà¹ˆà¸™ `llama3.1:3b`

## ğŸ¤ Contributing

Fork â†’ Branch â†’ Commit â†’ Push â†’ Pull Request

## ğŸ“ License

MIT License

## ğŸ™ Acknowledgments

Special thanks to:
- Meta AI for Llama 3.1
- Ollama team for local LLM runtime
- LangChain for the amazing framework
- Streamlit for the beautiful UI
- ChromaDB for vector storage

## ğŸ“§ Contact

**6amdev** â€¢ [GitHub](https://github.com/6amdev) â€¢ [Issues](https://github.com/6amdev/personal-ai-assistant/issues)

---

**Made with â¤ï¸ by [6amdev](https://github.com/6amdev)**

*Give it a star if you like it!* â­