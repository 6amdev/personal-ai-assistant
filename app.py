"""Personal AI Assistant - Main App with RAG"""
import streamlit as st
import tempfile
import os
from pathlib import Path

from src.ui import setup_page, show_header, show_sidebar, chat_interface, clear_chat_history
from src.llm import LLMHandler
from src.memory import MemoryHandler
from src.document_processor import DocumentProcessor


def main():
    setup_page()
    
    @st.cache_resource
    def init_components():
        """Initialize LLM and Memory"""
        llm = LLMHandler()
        memory = MemoryHandler()
        return llm, memory
    
    try:
        llm, memory = init_components()
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        st.info("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà!")
        st.code("ollama list", language="bash")
        st.stop()
    
    show_header()
    
    # Sidebar
    clear_chat, clear_memory, uploaded_files, docs_to_delete = show_sidebar(memory)
    
    # Handle clear chat
    if clear_chat:
        clear_chat_history()
        memory.clear_conversation()
    
    # Handle delete specific documents
    if docs_to_delete:
        for doc_source in docs_to_delete:
            deleted_count = memory.delete_by_source(doc_source)
            if deleted_count > 0:
                st.success(f"‚úÖ ‡∏•‡∏ö {doc_source} ‡πÅ‡∏•‡πâ‡∏ß ({deleted_count} chunks)")
                st.rerun()
    
    # Handle clear all documents
    if clear_memory:
        with st.spinner("üóëÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î..."):
            success = memory.clear_all_documents()
            
            if success:
                st.success("‚úÖ ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß!")
                st.cache_resource.clear()
                st.rerun()
            else:
                st.error("‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    
    # Handle file uploads
    if uploaded_files:
        process_uploaded_files(uploaded_files, memory)
    
    # Main chat
    chat_interface(llm, memory)
    
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        Made with ‚ù§Ô∏è using Ollama, LangChain & Streamlit
    </div>
    """, unsafe_allow_html=True)


def process_uploaded_files(uploaded_files, memory):
    """Process and store uploaded files with detailed progress"""
    
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ã‡πâ‡∏≥ üî•
    file_ids = [f.file_id for f in uploaded_files]
    processed_key = "processed_files"
    
    if processed_key not in st.session_state:
        st.session_state[processed_key] = set()
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    new_files = []
    for f in uploaded_files:
        if f.file_id not in st.session_state[processed_key]:
            new_files.append(f)
            st.session_state[processed_key].add(f.file_id)
    
    if not new_files:
        return  # ‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    detail_text = st.empty()
    
    processor = DocumentProcessor()
    total_files = len(new_files)
    all_chunks = []
    all_metadatas = []
    
    # Phase 1: ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    for idx, uploaded_file in enumerate(new_files):
        try:
            status_text.text(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô {uploaded_file.name}... ({idx+1}/{total_files})")
            
            # Save temp file
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            # Process
            status_text.text(f"üìù ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å {uploaded_file.name}...")
            chunks = processor.process_file(tmp_path)
            
            # ‡∏£‡∏ß‡∏° chunks
            all_chunks.extend(chunks)
            all_metadatas.extend([{'source': uploaded_file.name} for _ in chunks])
            
            detail_text.info(f"‚úÖ {uploaded_file.name}: {len(chunks)} chunks")
            
            # Cleanup
            os.unlink(tmp_path)
            
            # Update progress
            progress_bar.progress((idx + 1) / total_files * 0.4)
            
        except Exception as e:
            st.error(f"‚ùå {uploaded_file.name}: {e}")
    
    # Phase 2: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    if all_chunks:
        total_chunks = len(all_chunks)
        status_text.text(f"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {total_chunks} chunks...")
        
        try:
            import time
            start_time = time.time()
            
            progress_bar.progress(0.5)
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!
            memory.add_documents(all_chunks, all_metadatas)
            
            elapsed = time.time() - start_time
            
            progress_bar.progress(1.0)
            status_text.empty()
            detail_text.empty()
            
            st.success(f"‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ({total_chunks} chunks ‡∏à‡∏≤‡∏Å {total_files} ‡πÑ‡∏ü‡∏•‡πå)")
            st.info(f"‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (~{elapsed/total_chunks:.2f}s/chunk)")
            st.balloons()
            
            # ‡πÑ‡∏°‡πà rerun! ‡πÅ‡∏Ñ‡πà‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä sidebar üî•
            st.rerun()
            
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            detail_text.empty()
            st.error(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()