"""Personal AI Assistant - Main App with RAG"""
import streamlit as st
import tempfile
import os
from pathlib import Path

from src.ui import setup_page, show_header, show_sidebar, chat_interface, clear_chat_history
from src.llm import LLMHandler
from src.memory import MemoryHandler
from src.document_processor import DocumentProcessor


def main():
    setup_page()
    
    @st.cache_resource
    def init_components():
        """Initialize LLM and Memory"""
        llm = LLMHandler()
        memory = MemoryHandler()
        return llm, memory
    
    try:
        llm, memory = init_components()
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        st.info("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà!")
        st.code("ollama list", language="bash")
        st.stop()
    
    show_header()
    
    # Sidebar
    clear_chat, clear_memory, uploaded_files, docs_to_delete = show_sidebar(memory)
    
    # Handle clear chat
    if clear_chat:
        clear_chat_history()
        memory.clear_conversation()
    
    # Handle delete specific documents
    if docs_to_delete:
        for doc_source in docs_to_delete:
            deleted_count = memory.delete_by_source(doc_source)
            if deleted_count > 0:
                st.success(f"‚úÖ ‡∏•‡∏ö {doc_source} ‡πÅ‡∏•‡πâ‡∏ß ({deleted_count} chunks)")
                st.rerun()
    
    # Handle clear all documents
    if clear_memory:
        with st.spinner("üóëÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î..."):
            success = memory.clear_all_documents()
            
            if success:
                st.success("‚úÖ ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß!")
                st.cache_resource.clear()
                st.rerun()
            else:
                st.error("‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    
    # Handle file uploads
    if uploaded_files:
        process_uploaded_files(uploaded_files, memory)
    
    # Main chat
    chat_interface(llm, memory)
    
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        Made with ‚ù§Ô∏è using Ollama, LangChain & Streamlit
    </div>
    """, unsafe_allow_html=True)


def process_uploaded_files(uploaded_files, memory):
    """Process and store uploaded files"""
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    processor = DocumentProcessor()
    total_files = len(uploaded_files)
    total_chunks = 0
    all_chunks = []
    all_metadatas = []
    
    # Phase 1: ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    for idx, uploaded_file in enumerate(uploaded_files):
        try:
            status_text.text(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô {uploaded_file.name}... ({idx+1}/{total_files})")
            
            # Save temp file
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            # Process
            status_text.text(f"üìù ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å {uploaded_file.name}...")
            chunks = processor.process_file(tmp_path)
            
            # ‡∏£‡∏ß‡∏° chunks
            all_chunks.extend(chunks)
            all_metadatas.extend([{'source': uploaded_file.name} for _ in chunks])
            
            total_chunks += len(chunks)
            
            # Cleanup
            os.unlink(tmp_path)
            
            # Update progress
            progress_bar.progress((idx + 1) / total_files * 0.5)
            
        except Exception as e:
            st.error(f"‚ùå Error: {uploaded_file.name}: {e}")
    
    # Phase 2: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!) üî•
    if all_chunks:
        status_text.text(f"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {total_chunks} chunks...")
        progress_bar.progress(0.6)
        
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß! ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà loop!
            memory.add_documents(all_chunks, all_metadatas)
            
            # ‡πÄ‡∏™‡∏£‡πá‡∏à
            progress_bar.progress(1.0)
            status_text.empty()
            
            st.success(f"‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ({total_chunks} chunks ‡∏à‡∏≤‡∏Å {total_files} ‡πÑ‡∏ü‡∏•‡πå)")
            st.balloons()
            st.rerun()
            
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"‚ùå Error: {e}")


if __name__ == "__main__":
    main()